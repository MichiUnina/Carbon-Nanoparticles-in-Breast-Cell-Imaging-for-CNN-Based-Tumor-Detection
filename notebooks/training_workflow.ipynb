{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74abf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import timm\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, ConfusionMatrixDisplay, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dde6f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data(data, target_length):\n",
    "    \"\"\"Duplica casualmente le immagini per bilanciare le classi fino alla lunghezza target.\"\"\"\n",
    "    initial_data = data.copy()\n",
    "    while len(data) < target_length:\n",
    "        data.extend(random.sample(initial_data, min(len(initial_data), target_length - len(data))))\n",
    "    return data[:target_length]  # Assicura che la lunghezza sia esatta\n",
    "\n",
    "\n",
    "class BalancedCellDataset(Dataset):\n",
    "    def __init__(self, csv_files, dataset_type, image_column=\"AllChannels\", root_dir=\"\", transform=None, balance=True, crop_radius=50):\n",
    "        \"\"\"\n",
    "        Dataset personalizzato per caricare immagini dai CSV con bilanciamento opzionale e ritaglio centrato.\n",
    "\n",
    "        Args:\n",
    "        - csv_files (list): Lista dei file CSV [benigno, maligno].\n",
    "        - dataset_type (str): Indica \"train\", \"validation\" o \"test\".\n",
    "        - image_column (str): Colonna con i percorsi delle immagini.\n",
    "        - root_dir (str): Percorso base delle immagini.\n",
    "        - transform (callable, optional): Trasformazioni da applicare alle immagini.\n",
    "        - balance (bool): Se True, bilancia solo il training set.\n",
    "        - crop_radius (int): Raggio `r` per il ritaglio dell'immagine (default: 50 pixel).\n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "        self.root_dir = root_dir\n",
    "        self.crop_radius = crop_radius\n",
    "        self.min_size = (100, 100)  # Dimensione minima richiesta\n",
    "\n",
    "        benign_data = []\n",
    "        malignant_data = []\n",
    "\n",
    "        for csv_file, label, target_list in zip(csv_files, [0, 1], [benign_data, malignant_data]):\n",
    "            df = pd.read_csv(csv_file)\n",
    "            df[\"Set\"] = df[\"Set\"].str.strip().str.lower()\n",
    "            dataset_type = dataset_type.lower()\n",
    "            df = df[df[\"Set\"] == dataset_type]\n",
    "\n",
    "            for _, row in df.iterrows():\n",
    "                img_path = os.path.join(\n",
    "                    self.root_dir,\n",
    "                    str(row[\"TypeOfCell\"]),\n",
    "                    str(row[\"Nome Acquisizione\"]),\n",
    "                    str(int(row[\"Numero cellula\"])),  # Evita problemi con float\n",
    "                    row[image_column]\n",
    "                )\n",
    "                target_list.append((img_path, label))\n",
    "\n",
    "        if balance and dataset_type == \"train\":\n",
    "            max_length = max(len(benign_data), len(malignant_data))\n",
    "            self.data = balance_data(benign_data, max_length) + balance_data(malignant_data, max_length)\n",
    "            random.shuffle(self.data)  # Evita pattern nei dati\n",
    "        else:\n",
    "            self.data = benign_data + malignant_data\n",
    "\n",
    "    def pad_image_to_min_size(self, image, min_size=(100, 100)):\n",
    "        \"\"\"Aggiunge padding all'immagine se è più piccola delle dimensioni minime richieste.\"\"\"\n",
    "        h, w = image.shape[:2]\n",
    "        pad_h = max(0, min_size[0] - h)\n",
    "        pad_w = max(0, min_size[1] - w)\n",
    "\n",
    "        if pad_h > 0 or pad_w > 0:\n",
    "            # Calcola il padding su ogni lato per centrare l'immagine\n",
    "            top = pad_h // 2\n",
    "            bottom = pad_h - top\n",
    "            left = pad_w // 2\n",
    "            right = pad_w - left\n",
    "\n",
    "            image = cv2.copyMakeBorder(image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=0)\n",
    "\n",
    "        return image\n",
    "\n",
    "    def crop_around_center(self, image, r):\n",
    "        \"\"\"Ritaglia un'area centrata sull'immagine in base al r specificato.\"\"\"\n",
    "        h, w = image.shape[:2]\n",
    "        if h < 2 * r or w < 2 * r:\n",
    "            raise ValueError(f\"L'immagine è troppo piccola ({h}x{w}) per il ritaglio con r={r}\")\n",
    "        x1, x2 = (w // 2 - r, w // 2 + r)\n",
    "        y1, y2 = (h // 2 - r, h // 2 + r)\n",
    "        return image[y1:y2, x1:x2]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.data[idx]\n",
    "\n",
    "        if not os.path.exists(img_path):\n",
    "            raise FileNotFoundError(f\"File non trovato: {img_path}\")\n",
    "\n",
    "        try:\n",
    "            image = np.load(img_path)  # Carica come NumPy array\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Errore nel caricamento dell'immagine {img_path}: {e}\")\n",
    "\n",
    "        # **Passo 1: Padding se necessario**\n",
    "        image = self.pad_image_to_min_size(image, self.min_size)\n",
    "\n",
    "        # **Passo 2: Ritaglio**\n",
    "        image = self.crop_around_center(image, self.crop_radius)\n",
    "\n",
    "        # **Passo 3: Trasformazioni**\n",
    "        if self.transform:\n",
    "            image = self.transform(image)  # Passa il NumPy array alle trasformazioni\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "class Normalize01(torch.nn.Module):\n",
    "    \"\"\"Normalizza i valori di un tensore tra 0 e 1.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, img):\n",
    "        min_val, max_val = img.min(), img.max()\n",
    "        return (img - min_val) / (max_val - min_val) if max_val > min_val else torch.zeros_like(img)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '()'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db164dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train_one_epoch(model, loader, criterion, optimizer, device, epoch, num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_train_labels = []\n",
    "    all_train_preds = []\n",
    "\n",
    "    print(f\"\\nEpoch {epoch + 1}/{num_epochs} - Training...\")\n",
    "\n",
    "    for batch_idx, (imgs, labels) in enumerate(loader):\n",
    "        imgs = imgs.type(torch.FloatTensor).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        model.zero_grad()\n",
    "\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        all_train_labels.extend(labels.detach().cpu().numpy())\n",
    "        all_train_preds.extend(predicted.detach().cpu().numpy())\n",
    "\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"Batch {batch_idx + 1}/{len(loader)} - Loss: {loss.item():.4f}\")\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    train_accuracy = accuracy_score(all_train_labels, all_train_preds)\n",
    "\n",
    "    print(f\"[TRAIN] Loss: {epoch_loss:.6f}, Accuracy: {train_accuracy:.4f}\")\n",
    "    return epoch_loss, train_accuracy\n",
    "\n",
    "\n",
    "def validate(model, loader, criterion, device, epoch, num_epochs):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_val_labels = []\n",
    "    all_val_preds = []\n",
    "\n",
    "    print(f\"\\nEpoch {epoch + 1}/{num_epochs} - Validation...\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (imgs, labels) in enumerate(loader):\n",
    "            imgs = imgs.type(torch.FloatTensor).to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * imgs.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "            all_val_labels.extend(labels.detach().cpu().numpy())\n",
    "            all_val_preds.extend(predicted.detach().cpu().numpy())\n",
    "\n",
    "            if (batch_idx + 1) % 10 == 0:\n",
    "                print(f\"Batch {batch_idx + 1}/{len(loader)} - Loss: {loss.item():.4f}\")\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    val_accuracy = accuracy_score(all_val_labels, all_val_preds)\n",
    "\n",
    "    print(f\"[VALIDATION] Loss: {epoch_loss:.6f}, Accuracy: {val_accuracy:.4f}\")\n",
    "    return epoch_loss, val_accuracy\n",
    "\n",
    "\n",
    "def train_loop(model, train_loader, val_loader, best_val_loss, optimizer, criterion, save_path, device, num_epochs=50):\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "        epoch_loss_train, train_accuracy = train_one_epoch(model, train_loader, criterion, optimizer, device, epoch, num_epochs)\n",
    "        epoch_loss_val, val_accuracy = validate(model, val_loader, criterion, device, epoch, num_epochs)\n",
    "\n",
    "        train_losses.append(epoch_loss_train)\n",
    "        val_losses.append(epoch_loss_val)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        # Salvataggio metriche\n",
    "        with open(os.path.join(save_path, 'classification_loss_train.txt'), 'a') as file:\n",
    "            file.write(str(epoch_loss_train) + '\\n')\n",
    "\n",
    "        with open(os.path.join(save_path, 'classification_acc_train.txt'), 'a') as file:\n",
    "            file.write(str(train_accuracy) + '\\n')\n",
    "\n",
    "        with open(os.path.join(save_path, 'classification_loss_val.txt'), 'a') as file:\n",
    "            file.write(str(epoch_loss_val) + '\\n')\n",
    "\n",
    "        with open(os.path.join(save_path, 'classification_acc_val.txt'), 'a') as file:\n",
    "            file.write(str(val_accuracy) + '\\n')\n",
    "\n",
    "        # Salva i pesi del modello\n",
    "        torch.save(model.state_dict(), os.path.join(save_path, 'training_weights.pth'))\n",
    "\n",
    "        if epoch_loss_val < best_val_loss:\n",
    "            best_val_loss = epoch_loss_val\n",
    "            torch.save(model.state_dict(), os.path.join(save_path, 'best_weights.pth'))\n",
    "            print(\"[INFO] Miglior modello salvato.\")\n",
    "\n",
    "    print(\"\\n[INFO] Training completato.\")\n",
    "    return model, train_losses, val_losses, train_accuracies, val_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf47b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "'''\n",
    "MICHI: FAI SOLO IL CHECK DEI VALORI DOPO LA ToTensor SE SONO VERAMENTE TRA 0 E 1 .. Se non lo sono, non fa niente! Tanto abbiamo la Normalize01\n",
    "'''\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def check_tensor_range(img):\n",
    "    \"\"\" Controlla se i valori del tensore sono nel range [0,1] dopo ToTensor. \"\"\"\n",
    "    if img.min() < 0 or img.max() > 1:\n",
    "        print(\"Warning: Tensor values are out of range [0,1] after ToTensor\")\n",
    "\n",
    "def pad_to_100x100(img):\n",
    "    \"\"\" Aggiunge padding nero per rendere l'immagine 100x100 se necessario. \"\"\"\n",
    "    _, h, w = img.shape  # Ottieni altezza e larghezza\n",
    "    if h == 100 and w == 100:\n",
    "        return img  # Se è già 100x100, non serve padding\n",
    "\n",
    "    # Calcola il padding necessario\n",
    "    pad_h = max(0, (100 - h) // 2)\n",
    "    pad_w = max(0, (100 - w) // 2)\n",
    "\n",
    "    # Applica il padding uniformemente sopra/sotto e a sinistra/destra\n",
    "    return transforms.functional.pad(img, (pad_w, pad_h, pad_w, pad_h), fill=0)\n",
    "\n",
    "# Trasformazioni per il training (include data augmentation)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: (check_tensor_range(x), x)[1]),  # Controllo range senza modificarlo\n",
    "    transforms.Resize((224, 224)),  # Porta l'immagine alla dimensione richiesta dal modello\n",
    "    transforms.RandomRotation(degrees=90),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    Normalize01()\n",
    "])\n",
    "\n",
    "# Trasformazioni per validazione e test\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: (check_tensor_range(x), x)[1]),\n",
    "    transforms.Resize((224, 224)),  # Porta tutto a 224x224 per il modello\n",
    "    Normalize01()\n",
    "])\n",
    "\n",
    "# Percorsi ai file CSV e directory di base\n",
    "csv_files = [\n",
    "    \"/content/Dataset Finale/csv/labeled/mcf7ControlCells_wo_mask_labeled.csv\",\n",
    "    \"/content/Dataset Finale/csv/labeled/mcf10aControlCells_wo_mask_labeled.csv\"\n",
    "]\n",
    "root_dir = \"/content/Dataset Finale\"\n",
    "\n",
    "csv_files_cross_test = [\n",
    "    \"/content/Dataset Finale/csv/labeled/mcf7CdExposed_wo_mask_labeled.csv\",\n",
    "    \"/content/Dataset Finale/csv/labeled/mcf10aCdExposed_wo_mask_labeled.csv\"\n",
    "]\n",
    "\n",
    "# Parametri\n",
    "image_column = \"CellNucleus\"\n",
    "\n",
    "# Creazione dei Dataset con crop_radius specifico per ogni set\n",
    "train_dataset = BalancedCellDataset(\n",
    "    csv_files,\n",
    "    dataset_type=\"train\",\n",
    "    image_column=image_column,\n",
    "    root_dir=root_dir,\n",
    "    transform=train_transform,\n",
    "    balance=True,\n",
    "    crop_radius=50  # Imposta r per ritagli 2rx2r\n",
    ")\n",
    "\n",
    "val_dataset = BalancedCellDataset(\n",
    "    csv_files,\n",
    "    dataset_type=\"validation\",\n",
    "    image_column=image_column,\n",
    "    root_dir=root_dir,\n",
    "    transform=val_test_transform,\n",
    "    crop_radius=50  # Mantiene r = 50 pixel → ritagli 100x100\n",
    ")\n",
    "\n",
    "test_dataset_1 = BalancedCellDataset(\n",
    "    csv_files,\n",
    "    dataset_type=\"test\",\n",
    "    image_column=image_column,\n",
    "    root_dir=root_dir,\n",
    "    transform=val_test_transform,\n",
    "    crop_radius=50  # Mantiene r = 50 pixel → ritagli 100x100\n",
    ")\n",
    "\n",
    "test_dataset_2 = BalancedCellDataset(\n",
    "    csv_files=csv_files_cross_test,\n",
    "    dataset_type=\"test\",\n",
    "    image_column=image_column,\n",
    "    root_dir=root_dir,\n",
    "    transform=val_test_transform,\n",
    "    crop_radius=50  # Mantiene r = 50 pixel → ritagli 100x100\n",
    ")\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "# Creazione dei DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader_1 = DataLoader(test_dataset_1, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader_2 = DataLoader(test_dataset_2, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Configura il numero di canali di input\n",
    "num_input_channels = 2  # Cambia a 2 se hai immagini bic-anale\n",
    "num_classes = 2  # Numero di classi nel dataset\n",
    "\n",
    "print(\"Caricamento del modello EfficientNetB0 con timm...\")\n",
    "model = timm.create_model('efficientnet_b0', pretrained=True, in_chans=num_input_channels, num_classes=num_classes)\n",
    "\n",
    "# Sposta il modello su GPU se disponibile\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Modello EfficientNetB0 caricato e adattato per {num_input_channels} canali di input.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b47a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "#  Loop di Training & Validazione\n",
    "# ===========================\n",
    "\n",
    "import os\n",
    "save_path = \"/content/drive/MyDrive/DeepLearningResults/\"\n",
    "\n",
    "# Creazione della directory se non esiste\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "# Criterio di perdita (CrossEntropyLoss per classificazione)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Ottimizzatore (Adam con parametri standard)\n",
    "# Cambiamo il learning rate per l'Adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4,betas=(0.9, 0.999), weight_decay=1e-4)\n",
    "\n",
    "# Numero di epoche\n",
    "num_epochs = 50\n",
    "\n",
    "best_val_loss = float('inf')  # Inizializza con un valore molto alto per il primo confronto\n",
    "\n",
    "# Avvia il training e ottieni le metriche per il plotting\n",
    "model, train_losses, val_losses, train_accuracies, val_accuracies = train_loop(\n",
    "    model, train_loader, val_loader, best_val_loss, optimizer, criterion, save_path, device, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8f3b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_curves(train_losses, val_losses, train_accuracies, val_accuracies):\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "    # Plot della Loss\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_losses, label=\"Train Loss\", linewidth=2, color='blue')\n",
    "    plt.plot(epochs, val_losses, label=\"Validation Loss\", linewidth=2, color='orange')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training & Validation Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    # Plot dell'Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, train_accuracies, label=\"Train Accuracy\", linewidth=2, color='blue')\n",
    "    plt.plot(epochs, val_accuracies, label=\"Validation Accuracy\", linewidth=2, color='orange')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Training & Validation Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "\n",
    "    # Mostra il grafico\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Genera i grafici senza smoothing\n",
    "plot_training_curves(train_losses, val_losses, train_accuracies, val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaf328d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione di valutazione\n",
    "def evaluate_model(model, test_loader, device, save_path, test_set_name):\n",
    "    model.load_state_dict(torch.load(save_path + 'best_weights.pth'))\n",
    "    test_save_path = os.path.join(save_path, test_set_name)\n",
    "    os.makedirs(test_save_path, exist_ok=True)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device, dtype=torch.float32), labels.to(device)\n",
    "\n",
    "        with torch.no_grad():  # Disattiva grad solo per inferenza standard\n",
    "            outputs = model(images)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            predicted = torch.argmax(probs, dim=1)\n",
    "\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_probs.extend(probs[:, 1].cpu().numpy())\n",
    "\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_probs = np.array(all_probs)\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average=\"binary\", zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average=\"binary\", zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average=\"binary\", zero_division=0)\n",
    "    auc = roc_auc_score(all_labels, all_probs)\n",
    "\n",
    "    print(\"\\nMetriche di valutazione:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "    print(f\"AUC: {auc:.4f}\")\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(cmap=\"Blues\", values_format=\"d\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "    return accuracy, precision, recall, f1, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9196d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eseguire l'inferenza sui test set\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Eseguo l'inferenza sul primo test set...\")\n",
    "test1_accuracy, test1_precision, test1_recall, test1_f1, test1_auc = evaluate_model(model, test_loader_1, device, save_path, \"test_set_1\")\n",
    "\n",
    "print(\"\\nEseguo l'inferenza sul secondo test set...\")\n",
    "test2_accuracy, test2_precision, test2_recall, test2_f1, test2_auc = evaluate_model(model, test_loader_2, device, save_path, \"test_set_2\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
